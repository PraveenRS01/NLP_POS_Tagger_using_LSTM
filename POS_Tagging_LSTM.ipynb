{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre' 'Vinken' ',' '61' 'years' 'old' ',' 'will' 'join' 'the' 'board'\n",
      " 'as' 'a' 'nonexecutive' 'director' 'Nov.' '29' '.']\n",
      "['NNP' 'NNP' ',' 'CD' 'NNS' 'JJ' ',' 'MD' 'VB' 'DT' 'NN' 'IN' 'DT' 'JJ'\n",
      " 'NN' 'NNP' 'CD' '.']\n"
     ]
    }
   ],
   "source": [
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    " \n",
    "print(sentences[0])\n",
    "print(sentence_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_sentences, \n",
    " test_sentences, \n",
    " train_tags, \n",
    " test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    " \n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    " \n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1448, 8001, 8141, 3367, 8664, 6308, 5316, 6641, 6491, 8246, 2244, 8661, 355, 974, 3044, 4605, 7642, 5525, 912, 3890, 2892, 8001, 4599, 4869, 4515, 3942, 13, 6624, 6205, 3832, 1386, 3857, 4927, 2892, 8723, 2207, 1265, 6980, 737, 9597, 7306, 6789, 8246, 4593, 6550, 1715, 4927, 4266, 9597, 4850, 7306, 9766, 1959, 7585, 4604, 6912]\n",
      "[5138, 7963, 4736, 2320, 3963, 924, 9597, 3762, 9985, 5715, 9707, 9844, 2244, 2661, 1, 6912]\n",
      "[30, 26, 40, 8, 18, 29, 39, 2, 41, 28, 20, 43, 14, 30, 11, 44, 8, 13, 13, 33, 14, 26, 41, 31, 14, 8, 42, 30, 26, 30, 40, 8, 31, 14, 41, 8, 10, 42, 8, 19, 42, 8, 28, 30, 41, 24, 31, 14, 19, 14, 42, 41, 30, 40, 32, 7]\n",
      "[5, 26, 40, 41, 1, 29, 19, 26, 41, 29, 1, 13, 20, 18, 40, 7]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    " \n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    " \n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    " \n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "for s in test_tags:\n",
    "    test_tags_y.append([tag2index[t] for t in s])\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)  # 271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1448 8001 8141 3367 8664 6308 5316 6641 6491 8246 2244 8661  355  974\n",
      " 3044 4605 7642 5525  912 3890 2892 8001 4599 4869 4515 3942   13 6624\n",
      " 6205 3832 1386 3857 4927 2892 8723 2207 1265 6980  737 9597 7306 6789\n",
      " 8246 4593 6550 1715 4927 4266 9597 4850 7306 9766 1959 7585 4604 6912\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[5138 7963 4736 2320 3963  924 9597 3762 9985 5715 9707 9844 2244 2661\n",
      "    1 6912    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[30 26 40  8 18 29 39  2 41 28 20 43 14 30 11 44  8 13 13 33 14 26 41 31\n",
      " 14  8 42 30 26 30 40  8 31 14 41  8 10 42  8 19 42  8 28 30 41 24 31 14\n",
      " 19 14 42 41 30 40 32  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "[ 5 26 40 41  1 29 19 26 41 29  1 13 20 18 40  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    " \n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 125, 128)          1295744   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 125, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 125, 47)           24111     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 125, 47)           0         \n",
      "=================================================================\n",
      "Total params: 2,108,335\n",
      "Trainable params: 2,108,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy', ignore_class_accuracy(0)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2504 samples, validate on 627 samples\n",
      "Epoch 1/40\n",
      "2504/2504 [==============================] - 63s 25ms/step - loss: 1.5466 - accuracy: 0.7576 - ignore_accuracy: 0.0510 - val_loss: 0.7647 - val_accuracy: 0.8180 - val_ignore_accuracy: 0.1293\n",
      "Epoch 2/40\n",
      "2504/2504 [==============================] - 90s 36ms/step - loss: 0.7029 - accuracy: 0.8006 - ignore_accuracy: 0.0916 - val_loss: 0.6826 - val_accuracy: 0.8013 - val_ignore_accuracy: 0.1121\n",
      "Epoch 3/40\n",
      "2504/2504 [==============================] - 98s 39ms/step - loss: 0.6577 - accuracy: 0.8175 - ignore_accuracy: 0.1322 - val_loss: 0.6516 - val_accuracy: 0.8185 - val_ignore_accuracy: 0.1334\n",
      "Epoch 4/40\n",
      "2504/2504 [==============================] - 98s 39ms/step - loss: 0.6322 - accuracy: 0.8206 - ignore_accuracy: 0.1358 - val_loss: 0.6317 - val_accuracy: 0.8194 - val_ignore_accuracy: 0.1356\n",
      "Epoch 5/40\n",
      "2504/2504 [==============================] - 97s 39ms/step - loss: 0.6133 - accuracy: 0.8219 - ignore_accuracy: 0.1393 - val_loss: 0.6131 - val_accuracy: 0.8207 - val_ignore_accuracy: 0.1419\n",
      "Epoch 6/40\n",
      "2504/2504 [==============================] - 96s 39ms/step - loss: 0.5974 - accuracy: 0.8262 - ignore_accuracy: 0.1585 - val_loss: 0.6007 - val_accuracy: 0.8264 - val_ignore_accuracy: 0.1665\n",
      "Epoch 7/40\n",
      "2504/2504 [==============================] - 99s 39ms/step - loss: 0.5833 - accuracy: 0.8338 - ignore_accuracy: 0.1936 - val_loss: 0.5877 - val_accuracy: 0.8366 - val_ignore_accuracy: 0.2154\n",
      "Epoch 8/40\n",
      "2504/2504 [==============================] - 101s 40ms/step - loss: 0.5658 - accuracy: 0.8515 - ignore_accuracy: 0.2798 - val_loss: 0.5668 - val_accuracy: 0.8643 - val_ignore_accuracy: 0.3496\n",
      "Epoch 9/40\n",
      "2504/2504 [==============================] - 98s 39ms/step - loss: 0.5379 - accuracy: 0.8734 - ignore_accuracy: 0.3860 - val_loss: 0.5310 - val_accuracy: 0.8786 - val_ignore_accuracy: 0.4189\n",
      "Epoch 10/40\n",
      "2504/2504 [==============================] - 94s 38ms/step - loss: 0.4909 - accuracy: 0.8849 - ignore_accuracy: 0.4418 - val_loss: 0.4718 - val_accuracy: 0.8888 - val_ignore_accuracy: 0.4679\n",
      "Epoch 11/40\n",
      "2504/2504 [==============================] - 95s 38ms/step - loss: 0.4231 - accuracy: 0.8970 - ignore_accuracy: 0.5015 - val_loss: 0.3976 - val_accuracy: 0.8985 - val_ignore_accuracy: 0.5146\n",
      "Epoch 12/40\n",
      "2504/2504 [==============================] - 101s 40ms/step - loss: 0.3451 - accuracy: 0.9097 - ignore_accuracy: 0.5638 - val_loss: 0.3223 - val_accuracy: 0.9148 - val_ignore_accuracy: 0.5933\n",
      "Epoch 13/40\n",
      "2504/2504 [==============================] - 104s 42ms/step - loss: 0.2711 - accuracy: 0.9296 - ignore_accuracy: 0.6600 - val_loss: 0.2559 - val_accuracy: 0.9345 - val_ignore_accuracy: 0.6871\n",
      "Epoch 14/40\n",
      "2504/2504 [==============================] - 94s 37ms/step - loss: 0.2068 - accuracy: 0.9510 - ignore_accuracy: 0.7640 - val_loss: 0.2034 - val_accuracy: 0.9531 - val_ignore_accuracy: 0.7765\n",
      "Epoch 15/40\n",
      "2504/2504 [==============================] - 91s 37ms/step - loss: 0.1552 - accuracy: 0.9666 - ignore_accuracy: 0.8390 - val_loss: 0.1636 - val_accuracy: 0.9614 - val_ignore_accuracy: 0.8163\n",
      "Epoch 16/40\n",
      "2504/2504 [==============================] - 96s 38ms/step - loss: 0.1166 - accuracy: 0.9758 - ignore_accuracy: 0.8829 - val_loss: 0.1362 - val_accuracy: 0.9686 - val_ignore_accuracy: 0.8506\n",
      "Epoch 17/40\n",
      "2504/2504 [==============================] - 104s 41ms/step - loss: 0.0890 - accuracy: 0.9821 - ignore_accuracy: 0.9141 - val_loss: 0.1160 - val_accuracy: 0.9726 - val_ignore_accuracy: 0.8691\n",
      "Epoch 18/40\n",
      "2504/2504 [==============================] - 98s 39ms/step - loss: 0.0691 - accuracy: 0.9863 - ignore_accuracy: 0.9337 - val_loss: 0.1034 - val_accuracy: 0.9759 - val_ignore_accuracy: 0.8853\n",
      "Epoch 19/40\n",
      "2504/2504 [==============================] - 105s 42ms/step - loss: 0.0554 - accuracy: 0.9891 - ignore_accuracy: 0.9474 - val_loss: 0.0945 - val_accuracy: 0.9778 - val_ignore_accuracy: 0.8944\n",
      "Epoch 20/40\n",
      "2504/2504 [==============================] - 104s 42ms/step - loss: 0.0453 - accuracy: 0.9913 - ignore_accuracy: 0.9579 - val_loss: 0.0880 - val_accuracy: 0.9785 - val_ignore_accuracy: 0.8974\n",
      "Epoch 21/40\n",
      "2504/2504 [==============================] - 110s 44ms/step - loss: 0.0380 - accuracy: 0.9925 - ignore_accuracy: 0.9641 - val_loss: 0.0837 - val_accuracy: 0.9797 - val_ignore_accuracy: 0.9034\n",
      "Epoch 22/40\n",
      "2504/2504 [==============================] - 105s 42ms/step - loss: 0.0322 - accuracy: 0.9936 - ignore_accuracy: 0.9691 - val_loss: 0.0805 - val_accuracy: 0.9801 - val_ignore_accuracy: 0.9052\n",
      "Epoch 23/40\n",
      "2504/2504 [==============================] - 120s 48ms/step - loss: 0.0278 - accuracy: 0.9945 - ignore_accuracy: 0.9735 - val_loss: 0.0780 - val_accuracy: 0.9808 - val_ignore_accuracy: 0.9086\n",
      "Epoch 24/40\n",
      "2504/2504 [==============================] - 114s 45ms/step - loss: 0.0242 - accuracy: 0.9952 - ignore_accuracy: 0.9770 - val_loss: 0.0760 - val_accuracy: 0.9810 - val_ignore_accuracy: 0.9093\n",
      "Epoch 25/40\n",
      "2504/2504 [==============================] - 115s 46ms/step - loss: 0.0214 - accuracy: 0.9958 - ignore_accuracy: 0.9797 - val_loss: 0.0759 - val_accuracy: 0.9809 - val_ignore_accuracy: 0.9088\n",
      "Epoch 26/40\n",
      "2504/2504 [==============================] - 113s 45ms/step - loss: 0.0190 - accuracy: 0.9963 - ignore_accuracy: 0.9818 - val_loss: 0.0749 - val_accuracy: 0.9812 - val_ignore_accuracy: 0.9102\n",
      "Epoch 27/40\n",
      "2504/2504 [==============================] - 112s 45ms/step - loss: 0.0171 - accuracy: 0.9967 - ignore_accuracy: 0.9838 - val_loss: 0.0736 - val_accuracy: 0.9817 - val_ignore_accuracy: 0.9124\n",
      "Epoch 28/40\n",
      "2504/2504 [==============================] - 111s 44ms/step - loss: 0.0155 - accuracy: 0.9970 - ignore_accuracy: 0.9853 - val_loss: 0.0732 - val_accuracy: 0.9819 - val_ignore_accuracy: 0.9136\n",
      "Epoch 29/40\n",
      "2504/2504 [==============================] - 115s 46ms/step - loss: 0.0141 - accuracy: 0.9973 - ignore_accuracy: 0.9867 - val_loss: 0.0725 - val_accuracy: 0.9821 - val_ignore_accuracy: 0.9147\n",
      "Epoch 30/40\n",
      "2504/2504 [==============================] - 110s 44ms/step - loss: 0.0127 - accuracy: 0.9975 - ignore_accuracy: 0.9880 - val_loss: 0.0723 - val_accuracy: 0.9819 - val_ignore_accuracy: 0.9138\n",
      "Epoch 31/40\n",
      "2504/2504 [==============================] - 108s 43ms/step - loss: 0.0116 - accuracy: 0.9978 - ignore_accuracy: 0.9890 - val_loss: 0.0727 - val_accuracy: 0.9823 - val_ignore_accuracy: 0.9155\n",
      "Epoch 32/40\n",
      "2504/2504 [==============================] - 123s 49ms/step - loss: 0.0107 - accuracy: 0.9980 - ignore_accuracy: 0.9900 - val_loss: 0.0732 - val_accuracy: 0.9823 - val_ignore_accuracy: 0.9154\n",
      "Epoch 33/40\n",
      "2504/2504 [==============================] - 135s 54ms/step - loss: 0.0098 - accuracy: 0.9982 - ignore_accuracy: 0.9910 - val_loss: 0.0727 - val_accuracy: 0.9824 - val_ignore_accuracy: 0.9159\n",
      "Epoch 34/40\n",
      "2504/2504 [==============================] - 147s 59ms/step - loss: 0.0091 - accuracy: 0.9983 - ignore_accuracy: 0.9918 - val_loss: 0.0743 - val_accuracy: 0.9820 - val_ignore_accuracy: 0.9142\n",
      "Epoch 35/40\n",
      "2504/2504 [==============================] - 148s 59ms/step - loss: 0.0084 - accuracy: 0.9985 - ignore_accuracy: 0.9926 - val_loss: 0.0742 - val_accuracy: 0.9823 - val_ignore_accuracy: 0.9155\n",
      "Epoch 36/40\n",
      "2504/2504 [==============================] - 144s 58ms/step - loss: 0.0079 - accuracy: 0.9985 - ignore_accuracy: 0.9928 - val_loss: 0.0757 - val_accuracy: 0.9820 - val_ignore_accuracy: 0.9145\n",
      "Epoch 37/40\n",
      "2504/2504 [==============================] - 150s 60ms/step - loss: 0.0073 - accuracy: 0.9987 - ignore_accuracy: 0.9937 - val_loss: 0.0750 - val_accuracy: 0.9823 - val_ignore_accuracy: 0.9153\n",
      "Epoch 38/40\n",
      "2504/2504 [==============================] - 147s 59ms/step - loss: 0.0068 - accuracy: 0.9988 - ignore_accuracy: 0.9942 - val_loss: 0.0744 - val_accuracy: 0.9823 - val_ignore_accuracy: 0.9155\n",
      "Epoch 39/40\n",
      "2504/2504 [==============================] - 146s 58ms/step - loss: 0.0062 - accuracy: 0.9990 - ignore_accuracy: 0.9951 - val_loss: 0.0766 - val_accuracy: 0.9821 - val_ignore_accuracy: 0.9145\n",
      "Epoch 40/40\n",
      "2504/2504 [==============================] - 218s 87ms/step - loss: 0.0058 - accuracy: 0.9991 - ignore_accuracy: 0.9954 - val_loss: 0.0771 - val_accuracy: 0.9821 - val_ignore_accuracy: 0.9150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x251614aaf28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), batch_size=128, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pos_tagger.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 17s 22ms/step\n",
      "accuracy: 98.20792078971863\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'should', 'speak', 'to', 'the', 'principal', 'about', 'this', 'incident', '.']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    \"I should speak to the principal about this incident .\".split()\n",
    "]\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5049 8812 1104 3890 8001 7914 3954 7716 9408 6912    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    " \n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.19085734e-07 7.02968426e-03 3.17033427e-03 ... 4.63619401e-08\n",
      "   1.45397706e-07 1.05748586e-04]\n",
      "  [5.56370416e-09 1.89385731e-02 1.20124989e-03 ... 5.73293235e-08\n",
      "   3.14482918e-06 1.98203761e-05]\n",
      "  [1.20179648e-05 4.01033030e-05 1.57566537e-04 ... 6.57654891e-05\n",
      "   1.17047566e-05 7.34910063e-05]\n",
      "  ...\n",
      "  [9.99986172e-01 8.48272262e-17 9.35486688e-11 ... 5.46038095e-08\n",
      "   4.01132354e-08 4.48325460e-10]\n",
      "  [9.99979496e-01 1.46127967e-16 1.48098159e-10 ... 5.14599172e-08\n",
      "   5.72895544e-08 9.13636278e-10]\n",
      "  [9.99968529e-01 2.46559671e-16 2.32060746e-10 ... 4.94552346e-08\n",
      "   7.64795161e-08 1.71940306e-09]]] (1, 125, 47)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PRP', 'MD', 'VB', 'TO', 'DT', 'NN', 'IN', 'DT', 'NN', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7bbb04bf6d232ad12d8b5e73d638bbc2dda13a739e08bddb5c98a601a337eaa"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
